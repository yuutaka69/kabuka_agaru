import streamlit as st
import pandas as pd
import joblib
import numpy as np
import os
import lightgbm as lgb # ãƒ¢ãƒ‡ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§ã®ãŸã‚

# --- è¨­å®š ---
# Streamlitã‚¢ãƒ—ãƒªã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã¨ã—ãŸãƒ‘ã‚¹
# GitHubãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆã«streamlit_app.pyãŒã‚ã‚Šã€
# data/modified/ ã®ä¸­ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹æ§‹é€ ã‚’æƒ³å®šã€‚
DATA_DIR = "data/modified" # è¤‡æ•°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå…¥ã£ã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
MODEL_FILENAME = "lgbm_stock_predictor.joblib" # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¯streamlit_app.pyã¨åŒã˜éšå±¤ã‚’æƒ³å®š

# --- é–¢æ•°: ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ ---

@st.cache_resource # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã¯ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘è¡Œã†ã‚ˆã†ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_model_and_features(model_path):
    """ãƒ¢ãƒ‡ãƒ«ã¨ã€è¨“ç·´æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚"""
    try:
        loaded_content = joblib.load(model_path)
        if isinstance(loaded_content, tuple) and len(loaded_content) == 2:
            model, feature_names = loaded_content
            st.success(f"ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚ç‰¹å¾´é‡æ•°: {len(feature_names)}")
            return model, feature_names
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ç›´æ¥å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ä»¥å¤–ã‚’ç‰¹å¾´é‡ã¨ä»®å®šã—ã¾ã™ã€‚")
            return loaded_content, None # ãƒ¢ãƒ‡ãƒ«ã®ã¿ã‚’è¿”ã™
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {model_path}")
        st.stop()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

@st.cache_data # ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ã‚‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ (éŠ˜æŸ„ã”ã¨ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥)
def load_stock_data(data_filepath):
    """æŒ‡å®šã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€LightGBMãŒæ‰±ãˆã‚‹ã‚ˆã†ã«å‰å‡¦ç†ã‚’è¡Œã†ã€‚"""
    try:
        df = pd.read_csv(data_filepath, index_col='Date', parse_dates=True)
        df.dropna(axis='columns', how='all', inplace=True) # ç©ºã®åˆ—ã‚’å‰Šé™¤
        df.replace([np.inf, -np.inf], np.nan, inplace=True) # ç„¡é™å¤§ã‚’NaNã«
        st.success(f"'{os.path.basename(data_filepath)}' ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚è¡Œæ•°: {len(df)}")
        return df
    except FileNotFoundError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{data_filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

# --- Streamlit UIã®æ§‹ç¯‰ ---

st.title("ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€è¤‡æ•°ã®éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å°†æ¥ã®æ ªä¾¡ï¼ˆæŒ‡å®šã•ã‚ŒãŸæœŸé–“ã§ã®ä¸Šæ˜‡ï¼‰ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

# ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«ä¸€åº¦ã ã‘ï¼‰
model, trained_feature_names = load_model_and_features(MODEL_FILENAME)

st.sidebar.header("ã‚¢ãƒ—ãƒªæƒ…å ±")
st.sidebar.write(f"ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: `{MODEL_FILENAME}`")
st.sidebar.write(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: `{DATA_DIR}`")
st.sidebar.write(f"LightGBMãƒãƒ¼ã‚¸ãƒ§ãƒ³: `{lgb.__version__}`")
st.sidebar.markdown("---")

st.header("éŠ˜æŸ„é¸æŠã¨äºˆæ¸¬è¨­å®š")

# åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã®å–å¾—
try:
    available_csv_files = [f for f in os.listdir(DATA_DIR) if f.endswith('_modified.csv')]
    if not available_csv_files:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{DATA_DIR}' ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’æŠ½å‡º (ä¾‹: QQQ_modified.csv -> QQQ)
    available_stocks = sorted([f.replace('_modified.csv', '') for f in available_csv_files])
    
    selected_stock = st.selectbox(
        "äºˆæ¸¬ã—ãŸã„éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        options=available_stocks,
        index=0 if available_stocks else None # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®éŠ˜æŸ„ã‚’é¸æŠ
    )

    if selected_stock:
        selected_data_filepath = os.path.join(DATA_DIR, f"{selected_stock}_modified.csv")
        df_selected_stock = load_stock_data(selected_data_filepath)
    else:
        st.warning("é¸æŠã§ãã‚‹éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

except FileNotFoundError:
    st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{DATA_DIR}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()
except Exception as e:
    st.error(f"ã‚¨ãƒ©ãƒ¼: éŠ˜æŸ„ãƒªã‚¹ãƒˆã®å–å¾—ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()


# ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™ç‰¹å¾´é‡åˆ—ã‚’æ±ºå®š
if trained_feature_names is not None:
    features_for_prediction = [col for col in trained_feature_names if col in df_selected_stock.columns]
    missing_features = [col for col in trained_feature_names if col not in df_selected_stock.columns]
    if missing_features:
        st.warning(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚ŒãŸéš›ã®ç‰¹å¾´é‡ã®ä¸€éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_features)}")
    if not features_for_prediction:
        st.error("ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ç‰¹å¾´é‡ã¨ä¸€è‡´ã™ã‚‹åˆ—ãŒã€é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
else:
    # ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å–å¾—ã§ããªã‹ã£ãŸå ´åˆã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ä»¥å¤–ã‚’å…¨ã¦ç‰¹å¾´é‡ã¨ä»®å®š
    potential_target_cols = [col for col in df_selected_stock.columns if 'target' in col]
    if potential_target_cols:
        features_for_prediction = [col for col in df_selected_stock.columns if col not in potential_target_cols]
    else:
        st.warning("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã‚’ç‰¹å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚å…¨ã¦ã®æ•°å€¤åˆ—ã‚’ç‰¹å¾´é‡ã¨ä»®å®šã—ã¾ã™ã€‚")
        features_for_prediction = df_selected_stock.select_dtypes(include=np.number).columns.tolist()


# äºˆæ¸¬å¯¾è±¡æ—¥ã®é¸æŠ
available_dates = df_selected_stock.index.unique().sort_values(ascending=False)

if available_dates.empty:
    st.warning("é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    st.stop()

default_date_index = 0
selected_date = st.selectbox(
    "äºˆæ¸¬ã‚’è¡Œã„ãŸã„æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ (ã“ã®æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã—ã¾ã™):",
    options=available_dates.date,
    index=default_date_index
)

# é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
prediction_data_series = df_selected_stock.loc[pd.to_datetime(selected_date)]

# äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®ã¿ã‚’æŠ½å‡ºã—ã€DataFrameå½¢å¼ã«æ•´å½¢
X_predict = pd.DataFrame([prediction_data_series[features_for_prediction].values], columns=features_for_prediction)

st.subheader(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ ({selected_stock}) - {selected_date} ã®ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
# ä¸»è¦ãªOHLCVã¨ä¸€éƒ¨ã®æŒ‡æ¨™ã‚’è¡¨ç¤º
display_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‹ã‚‰SMA, RSI, MACDé–¢é€£ã®åˆ—ã‚’æŠ½å‡ºã—ã¦è¡¨ç¤ºã«è¿½åŠ 
indicator_display_cols = [f for f in features_for_prediction if any(f.startswith(prefix) for prefix in ['SMA', 'RSI', 'MACD', 'stoch'])]
display_cols.extend(indicator_display_cols)
# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¦è¡¨ç¤º
existing_display_cols = [col for col in display_cols if col in prediction_data_series.index]
if not existing_display_cols:
    st.warning("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.dataframe(prediction_data_series[existing_display_cols].to_frame().T)
st.markdown("---")

# äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ“ˆ æ ªä¾¡ä¸Šæ˜‡ã‚’äºˆæ¸¬ã™ã‚‹"):
    with st.spinner("äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
        # NaNå€¤ãŒã‚ã‚‹ã‹ç¢ºèª (LightGBMã¯NaNã‚’æ‰±ãˆã‚‹ãŒã€å…¨ã¦NaNã®å ´åˆã¯è­¦å‘Š)
        if X_predict.isnull().all().all():
            st.error("é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ãŒå…¨ã¦NaNã®ãŸã‚ã€äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
        else:
            prediction_proba = model.predict_proba(X_predict)[:, 1][0]
            prediction_class = model.predict(X_predict)[0]

            st.subheader("äºˆæ¸¬çµæœ")
            if prediction_class == 1:
                st.success(f"**ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ï¼**")
                st.metric("ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")
            else:
                st.info(f"**ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«/ãƒã‚¬ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒä¸Šæ˜‡ã—ãªã„å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚**")
                st.metric("ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")

            st.markdown("---")
            st.subheader("äºˆæ¸¬ã«å½±éŸ¿ã—ãŸç‰¹å¾´é‡")
            if hasattr(model, 'feature_importances_') and model.feature_name_ is not None:
                feature_importance = pd.Series(model.feature_importances_, index=model.feature_name_)
                top_features = feature_importance[features_for_prediction].nlargest(15)
                st.bar_chart(top_features)
            else:
                st.warning("ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            st.markdown("---")
            st.info("â€» ã“ã®äºˆæ¸¬ã¯ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ãŸã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®æ ªä¾¡ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")