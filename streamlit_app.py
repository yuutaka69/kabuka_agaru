# streamlit_app.py (å…¨æ©Ÿèƒ½ã‚’å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«é›†ç´„)

import streamlit as st
import pandas as pd
import joblib
import numpy as np
import requests
import json
from pathlib import Path
import matplotlib.pyplot as plt
import mplfinance as mpf # æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºç”¨
import seaborn as sns # æ··åŒè¡Œåˆ—ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨

# --- è¨­å®š ---
# GitHub raw content URLã®ãƒ™ãƒ¼ã‚¹
GITHUB_RAW_URL_BASE = "https://raw.githubusercontent.com/yuutaka69/kabuka_agaru/main/"
# å…¨ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®URL
ALL_PERFORMANCE_JSON_URL = f"{GITHUB_RAW_URL_BASE}models/all_stock_model_performance.json"

# --- é–¢æ•°: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã) ---

@st.cache_data
def load_all_performance_data_from_github():
    """
    GitHubã‹ã‚‰å…¨ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    try:
        response = requests.get(ALL_PERFORMANCE_JSON_URL)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        perf_data = response.json()
        st.success(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ '{Path(ALL_PERFORMANCE_JSON_URL).name}' ã‚’GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return perf_data
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

@st.cache_resource
def load_model_and_features_from_github(stock_code, target_period):
    """
    GitHubã‹ã‚‰ç‰¹å®šã®LightGBMãƒ¢ãƒ‡ãƒ«ã¨è¨“ç·´æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    model_filename = f"lgbm_model_{stock_code}_{target_period}d.joblib"
    model_url = f"{GITHUB_RAW_URL_BASE}models/{model_filename}"

    try:
        response = requests.get(model_url)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        
        # joblib.load ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ©ã‚¤ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æœŸå¾…ã™ã‚‹ã®ã§ã€BytesIOã‚’ä½¿ã†
        from io import BytesIO
        loaded_content = joblib.load(BytesIO(response.content))

        if isinstance(loaded_content, tuple) and len(loaded_content) == 2:
            model, feature_names = loaded_content
            return model, feature_names
        else:
            st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_filename}' ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒã‚»ãƒƒãƒˆã§ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None, None
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ« '{model_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return None, None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

@st.cache_data
def load_stock_data_from_github(stock_code):
    """
    GitHubã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸéŠ˜æŸ„ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€LightGBMãŒæ‰±ãˆã‚‹ã‚ˆã†ã«å‰å‡¦ç†ã‚’è¡Œã†ã€‚
    ã“ã“ã§ã¯äºˆæ¸¬ã«å¿…è¦ãªOpen, High, Low, Close, Volumeä»¥å¤–ã®ç‰¹å¾´é‡ã‚‚ä¿æŒã™ã‚‹ã€‚
    """
    data_filename = f"{stock_code}_modified.csv"
    data_url = f"{GITHUB_RAW_URL_BASE}data/modified/{data_filename}"
    
    try:
        df = pd.read_csv(data_url, index_col='Date', parse_dates=True)
        df.dropna(axis='columns', how='all', inplace=True)
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        return df
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ '{data_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

# --- Streamlit UIã®æ§‹ç¯‰ ---

st.set_page_config(
    layout="wide",
    page_title="æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    initial_sidebar_state="expanded" # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’å¸¸ã«å±•é–‹
)

st.title("ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€**GitHubã«ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡çµæœ**ã‚’ä½¿ç”¨ã—ã¦ã€æ ªä¾¡äºˆæ¸¬æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚")

# å…¨ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’æœ€åˆã«ãƒ­ãƒ¼ãƒ‰
all_performance_data = load_all_performance_data_from_github()

if all_performance_data is None:
    st.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

# åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã®å–å¾—
available_stocks = sorted(list(all_performance_data.keys()))

if not available_stocks:
    st.error("GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã«éŠ˜æŸ„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«éŠ˜æŸ„é¸æŠã‚’é…ç½®
st.sidebar.header("éŠ˜æŸ„é¸æŠ")
selected_stock = st.sidebar.selectbox(
    "åˆ†æã—ãŸã„éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=available_stocks,
    index=0
)

# ã‚¿ãƒ–ã®ä½œæˆ
tab1, tab2 = st.tabs(["ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ğŸ“ˆ å€‹åˆ¥éŠ˜æŸ„è©³ç´°"])

# --- ã‚¿ãƒ–1: ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º ---
with tab1:
    st.header("ğŸ“Š æ ªä¾¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    st.markdown("ã“ã“ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã§ç¢ºèªã§ãã¾ã™ã€‚")

    ranking_data = []
    for stock_code, periods_data in all_performance_data.items():
        for period_str, model_data in periods_data.items():
            training_eval = model_data.get('training_evaluation', {})
            recent_eval = model_data.get('recent_data_evaluation', {})
            
            # å‹•çš„é–¾å€¤ã‚’å–å¾—
            target_col_pattern = f"target_{int(period_str.replace('d', ''))}d_"
            dynamic_threshold_str = "N/A"
            if 'target_0_metrics' in training_eval: # è¨“ç·´æ™‚ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‹ã‚‰å‹•çš„é–¾å€¤ã‚’è¦‹ã¤ã‘ã‚‹
                for key in training_eval['target_0_metrics'].keys(): # ä»®ã«target_0_metricsã«ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
                    if 'p' in key and target_col_pattern in key:
                         # ä¾‹: "target_120d_30.0p" -> "30.0p"
                        dynamic_threshold_str = key.split(target_col_pattern)[1] 
                        break
            
            # all_stock_model_performance.json ã« target_column_name ãŒè¿½åŠ ã•ã‚Œã¦ã„ã‚Œã°ã€ãã“ã‹ã‚‰ç›´æ¥å–å¾—ã§ãã‚‹
            if 'target_column_name' in training_eval:
                full_target_name = training_eval['target_column_name']
                # ä¾‹: 'target_120d_30.0p' ã‹ã‚‰ '30.0p' ã‚’æŠ½å‡º
                parts = full_target_name.split('_')
                if len(parts) > 2 and parts[1].endswith('d'):
                    dynamic_threshold_str = parts[2]
            elif 'target_column_name' in recent_eval: # ç›´è¿‘è©•ä¾¡ã®æ–¹ã«æƒ…å ±ãŒã‚ã‚‹å¯èƒ½æ€§ã‚‚è€ƒæ…®
                full_target_name = recent_eval['target_column_name']
                parts = full_target_name.split('_')
                if len(parts) > 2 and parts[1].endswith('d'):
                    dynamic_threshold_str = parts[2]

            ranking_data.append({
                'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': stock_code,
                'äºˆæ¸¬æœŸé–“ (æ—¥)': int(period_str.replace('d', '')),
                'ä¸Šæ˜‡é–¾å€¤': dynamic_threshold_str, # æ–°ã—ãè¿½åŠ 
                'è¨“ç·´Acc': training_eval.get('accuracy', np.nan),
                'è¨“ç·´AUC': training_eval.get('roc_auc_score', np.nan),
                'è¨“ç·´F1(1)': training_eval.get('class_1_metrics', {}).get('f1-score', np.nan),
                'ç›´è¿‘Acc': recent_eval.get('accuracy', np.nan),
                'ç›´è¿‘AUC': recent_eval.get('roc_auc_score', np.nan),
                'ç›´è¿‘F1(1)': recent_eval.get('f1_score_class_1', np.nan),
                'æœ€çµ‚äºˆæ¸¬æ—¥': recent_eval.get('most_recent_prediction_date', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬å€¤': recent_eval.get('most_recent_prediction_value', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': recent_eval.get('most_recent_prediction_proba', np.nan)
            })

    if ranking_data:
        df_ranking = pd.DataFrame(ranking_data)

        # ã‚½ãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        sort_by_options = {
            "ç›´è¿‘F1(1) (é™é †)": "ç›´è¿‘F1(1)",
            "è¨“ç·´F1(1) (é™é †)": "è¨“ç·´F1(1)",
            "ç›´è¿‘Acc (é™é †)": "ç›´è¿‘Acc",
            "è¨“ç·´Acc (é™é †)": "è¨“ç·´Acc",
            "äºˆæ¸¬æœŸé–“ (æ—¥) (æ˜‡é †)": "äºˆæ¸¬æœŸé–“ (æ—¥)",
            "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (æ˜‡é †)": "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰"
        }
        
        col1_rank, col2_rank = st.columns([1, 2])
        with col1_rank:
            sort_key_display = st.selectbox("ã‚½ãƒ¼ãƒˆåŸºæº–:", list(sort_by_options.keys()))
        
        sort_column = sort_by_options[sort_key_display]
        ascending = False if "é™é †" in sort_key_display else True

        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’é©åˆ‡ã«ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€NaNã®ã¾ã¾ã«ã—ã¦ãŠã
        numeric_cols = ['è¨“ç·´Acc', 'è¨“ç·´AUC', 'è¨“ç·´F1(1)', 'ç›´è¿‘Acc', 'ç›´è¿‘AUC', 'ç›´è¿‘F1(1)', 'æœ€çµ‚äºˆæ¸¬ç¢ºç‡']
        for col in numeric_cols:
            if col in df_ranking.columns:
                df_ranking[col] = pd.to_numeric(df_ranking[col], errors='coerce') # å¼·åˆ¶çš„ã«æ•°å€¤ã«å¤‰æ›ã€å¤‰æ›ã§ããªã„ã‚‚ã®ã¯NaNã«

        # ã‚½ãƒ¼ãƒˆå®Ÿè¡Œ
        df_ranking_sorted = df_ranking.sort_values(by=sort_column, ascending=ascending, na_position='last')

        st.markdown("---")
        st.subheader("å…¨ä½“ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        st.markdown("ï¼ˆå„æŒ‡æ¨™ã¯é«˜ã‘ã‚Œã°é«˜ã„ã»ã©è‰¯ã„å‚¾å‘ã‚’ç¤ºã—ã¾ã™ã€‚ï¼‰")

        # DataFrameã‚’Streamlitã§è¡¨ç¤ºã€‚style.formatã¯NaNã‚’è‡ªå‹•ã§ç„¡è¦–ã—ã¾ã™ã€‚
        st.dataframe(df_ranking_sorted.style.format({
            'è¨“ç·´Acc': "{:.2f}", 'è¨“ç·´AUC': "{:.2f}", 'è¨“ç·´F1(1)': "{:.2f}",
            'ç›´è¿‘Acc': "{:.2f}", 'ç›´è¿‘AUC': "{:.2f}", 'ç›´è¿‘F1(1)': "{:.2f}",
            'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': "{:.2%}"
        }), use_container_width=True)

        st.caption("â€» **ä¸Šæ˜‡é–¾å€¤**: Næ—¥å¾Œã«æ ªä¾¡ãŒã“ã®å‰²åˆä»¥ä¸Šä¸Šæ˜‡ã—ãŸå ´åˆã«ã€Œä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1ï¼‰ã€ã¨åˆ¤å®šã•ã‚Œã¾ã™ã€‚")
        st.caption("â€» æœ€çµ‚äºˆæ¸¬å€¤ãŒ1ã¯ä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ã€0ã¯éä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ã‚’ç¤ºã—ã¾ã™ã€‚")
        st.caption("â€» ç›´è¿‘F1(1)ãŒ NaN ã®å ´åˆã€ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã«ã‚¯ãƒ©ã‚¹1ã®ã‚µãƒ³ãƒ—ãƒ«ãŒãªã‹ã£ãŸã‹ã€è©•ä¾¡ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

    else:
        st.warning("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚GitHubã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- ã‚¿ãƒ–2: å€‹åˆ¥éŠ˜æŸ„è©³ç´° ---
with tab2:
    st.header(f"ğŸ“ˆ å€‹åˆ¥éŠ˜æŸ„è©³ç´°åˆ†æ: {selected_stock}")
    st.markdown("é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ã€å„äºˆæ¸¬æœŸé–“ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨æœ€æ–°äºˆæ¸¬ã€æ ªä¾¡æ¨ç§»ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

    df_selected_stock = load_stock_data_from_github(selected_stock)

    if df_selected_stock.empty:
        st.error(f"éŠ˜æŸ„ {selected_stock} ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    # æœ€æ–°ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã¨ãƒãƒ£ãƒ¼ãƒˆ (è¡¨ã¯å‰Šé™¤)
    st.subheader("ç›´è¿‘ã®æ ªä¾¡æ¨ç§»")
    # mplfinanceã§ãƒãƒ£ãƒ¼ãƒˆæç”»
    try:
        mc = mpf.make_marketcolors(up='red', down='blue', wick='inherit', edge='inherit', volume='in', inherit=True)
        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc)
        
        fig, axes = mpf.plot(
            df_selected_stock.tail(120), # ç›´è¿‘120æ—¥é–“ã®ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            type='candle',
            style=s,
            volume=True,
            figscale=1.5,
            returnfig=True
        )
        st.pyplot(fig)
    except Exception as e:
        st.warning(f"æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆã®æç”»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã‚‹ã‹ã€å½¢å¼ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")


    st.subheader("å„äºˆæ¸¬æœŸé–“ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨æœ€æ–°äºˆæ¸¬")

    periods_data = all_performance_data.get(selected_stock, {})
    if not periods_data:
        st.warning(f"éŠ˜æŸ„ {selected_stock} ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        sorted_periods = sorted([int(p.replace('d', '')) for p in periods_data.keys()])

        for target_period in sorted_periods:
            period_str = f"{target_period}d"
            model_data = periods_data[period_str]

            st.markdown(f"---")
            st.markdown(f"#### {target_period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«")

            # å‹•çš„é–¾å€¤ã‚’å–å¾—
            dynamic_threshold_str = "N/A"
            training_metrics = model_data.get('training_evaluation', {})
            recent_metrics = model_data.get('recent_data_evaluation', {})

            if 'target_column_name' in training_metrics:
                full_target_name = training_metrics['target_column_name']
                parts = full_target_name.split('_')
                if len(parts) > 2 and parts[1].endswith('d'):
                    dynamic_threshold_str = parts[2]
            elif 'target_column_name' in recent_metrics: # ç›´è¿‘è©•ä¾¡ã®æ–¹ã«æƒ…å ±ãŒã‚ã‚‹å¯èƒ½æ€§ã‚‚è€ƒæ…®
                full_target_name = recent_metrics['target_column_name']
                parts = full_target_name.split('_')
                if len(parts) > 2 and parts[1].endswith('d'):
                    dynamic_threshold_str = parts[2]
            
            st.markdown(f"ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€**{target_period}æ—¥å¾Œã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹ã‹**ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

            # è¨“ç·´æ™‚è©•ä¾¡
            st.markdown("##### è¨“ç·´æ™‚ã®è©•ä¾¡ (ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ)")
            
            if training_metrics:
                col_tr1, col_tr2 = st.columns(2)
                with col_tr1:
                    st.write(f"- **ç²¾åº¦ (Accuracy):** `{training_metrics.get('accuracy', np.nan):.2f}`")
                    st.write(f"- **ROC AUC ã‚¹ã‚³ã‚¢:** `{training_metrics.get('roc_auc_score', np.nan):.2f}`")
                with col_tr2:
                    st.markdown(f"**ã‚¯ãƒ©ã‚¹ 1 (ä¸Šæ˜‡ã™ã‚‹) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
                    class_1_train = training_metrics.get('class_1_metrics', {})
                    st.write(f"- é©åˆç‡ (Precision): `{class_1_train.get('precision', np.nan):.2f}`")
                    st.write(f"- å†ç¾ç‡ (Recall): `{class_1_train.get('recall', np.nan):.2f}`")
                    st.write(f"- F1ã‚¹ã‚³ã‚¢: `{class_1_train.get('f1-score', np.nan):.2f}`")
                st.caption("â€»ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ»è©•ä¾¡ã•ã‚ŒãŸéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")

                # æ··åŒè¡Œåˆ—ã®è¡¨ç¤º (è¨“ç·´æ™‚)
                cm_train = training_metrics.get('confusion_matrix', [[0,0],[0,0]])
                if cm_train:
                    st.markdown("##### æ··åŒè¡Œåˆ— (è¨“ç·´ãƒ‡ãƒ¼ã‚¿)")
                    fig_cm_train, ax_cm_train = plt.subplots(figsize=(6, 4))
                    sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=ax_cm_train,
                                xticklabels=['äºˆæ¸¬:éä¸Šæ˜‡ (0)', 'äºˆæ¸¬:ä¸Šæ˜‡ (1)'],
                                yticklabels=['å®Ÿéš›:éä¸Šæ˜‡ (0)', 'å®Ÿéš›:ä¸Šæ˜‡ (1)'])
                    ax_cm_train.set_title('è¨“ç·´æ™‚ Confusion Matrix')
                    ax_cm_train.set_ylabel('å®Ÿéš›')
                    ax_cm_train.set_xlabel('äºˆæ¸¬')
                    st.pyplot(fig_cm_train)
                else:
                    st.warning("è¨“ç·´æ™‚æ··åŒè¡Œåˆ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning("è¨“ç·´æ™‚è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

            # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬
            st.markdown("##### ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬")
            
            if recent_metrics:
                col_rc1, col_rc2 = st.columns(2)
                with col_rc1:
                    st.write(f"- **è©•ä¾¡æœŸé–“ (æ—¥æ•°):** `{recent_metrics.get('total_evaluated_days', 'N/A')}`")
                    st.write(f"- **ç²¾åº¦ (Accuracy):** `{recent_metrics.get('accuracy', np.nan):.2f}`")
                    st.write(f"- **ROC AUC ã‚¹ã‚³ã‚¢:** `{recent_metrics.get('roc_auc_score', np.nan):.2f}`")
                with col_rc2:
                    st.markdown(f"**ã‚¯ãƒ©ã‚¹ 1 (ä¸Šæ˜‡ã™ã‚‹) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
                    st.write(f"- é©åˆç‡ (Precision): `{recent_metrics.get('precision_class_1', np.nan):.2f}`")
                    st.write(f"- å†ç¾ç‡ (Recall): `{recent_metrics.get('recall_class_1', np.nan):.2f}`")
                    st.write(f"- F1ã‚¹ã‚³ã‚¢: `{recent_metrics.get('f1_score_class_1', np.nan):.2f}`")
                
                st.markdown(f"**æœ€æ–°ã®äºˆæ¸¬ ({recent_metrics.get('most_recent_prediction_date', 'N/A')}ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã):**")
                prediction_value = recent_metrics.get('most_recent_prediction_value', 'N/A')
                prediction_proba = recent_metrics.get('most_recent_prediction_proba', np.nan)
                
                if prediction_value == 1:
                    st.success(f"**ğŸ“ˆ ä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ï¼** ({target_period}æ—¥å¾Œã¾ã§ã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„)")
                    st.metric("äºˆæ¸¬ç¢ºç‡", f"{prediction_proba:.2%}" if not np.isnan(prediction_proba) else 'N/A')
                elif prediction_value == 0:
                    st.info(f"**ğŸ“‰ éä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«** ({target_period}æ—¥å¾Œã¾ã§ã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„)")
                    st.metric("äºˆæ¸¬ç¢ºç‡", f"{prediction_proba:.2%}" if not np.isnan(prediction_proba) else 'N/A')
                else:
                    st.warning("æœ€æ–°ã®äºˆæ¸¬å€¤ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

                st.caption("â€»ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚ŒãŸç›´è¿‘ã®æœŸé–“ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")

                # æ··åŒè¡Œåˆ—ã®è¡¨ç¤º (ç›´è¿‘ãƒ‡ãƒ¼ã‚¿)
                cm_recent = recent_metrics.get('confusion_matrix', [[0,0],[0,0]])
                if cm_recent:
                    st.markdown("##### æ··åŒè¡Œåˆ— (ç›´è¿‘ãƒ‡ãƒ¼ã‚¿)")
                    fig_cm_recent, ax_cm_recent = plt.subplots(figsize=(6, 4))
                    sns.heatmap(cm_recent, annot=True, fmt='d', cmap='Blues', ax=ax_cm_recent,
                                xticklabels=['äºˆæ¸¬:éä¸Šæ˜‡ (0)', 'äºˆæ¸¬:ä¸Šæ˜‡ (1)'],
                                yticklabels=['å®Ÿéš›:éä¸Šæ˜‡ (0)', 'å®Ÿéš›:ä¸Šæ˜‡ (1)'])
                    ax_cm_recent.set_title('ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ Confusion Matrix')
                    ax_cm_recent.set_ylabel('å®Ÿéš›')
                    ax_cm_recent.set_xlabel('äºˆæ¸¬')
                    st.pyplot(fig_cm_recent)
                else:
                    st.warning("ç›´è¿‘ãƒ‡ãƒ¼ã‚¿æ··åŒè¡Œåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning("ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

st.sidebar.markdown("---")
st.sidebar.info("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: GitHubã®å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒª")
st.sidebar.markdown("---")
st.sidebar.write("Developed with â¤ï¸ by Yuu") # ã‚ãªãŸã®åå‰ã«å¤‰æ›´ã—ã¦ãã ã•ã„
