import streamlit as st
import pandas as pd
import joblib
import numpy as np
import os
import lightgbm as lgb
from pathlib import Path
import matplotlib.pyplot as plt
import mplfinance as mpf
import json

# --- è¨­å®š ---
MODELS_DIR = Path("models") # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹JSONã®å…±é€šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ä»®å®š
DATA_DIR = Path("data/modified")

# --- é–¢æ•°: ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ ---

@st.cache_resource
def load_model_and_features(model_path):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‘ã‚¹ã‹ã‚‰LightGBMãƒ¢ãƒ‡ãƒ«ã¨è¨“ç·´æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    if not model_path.exists():
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: `{model_path}`")
        st.stop()
    try:
        loaded_content = joblib.load(model_path)
        if isinstance(loaded_content, tuple) and len(loaded_content) == 2:
            model, feature_names = loaded_content
            st.success(f"ãƒ¢ãƒ‡ãƒ« '{model_path.name}' ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚ç‰¹å¾´é‡æ•°: {len(feature_names)}")
            return model, feature_names
        else:
            st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_path.name}' ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒã‚»ãƒƒãƒˆã§ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.stop()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

@st.cache_data
def load_stock_data(data_filepath):
    """
    æŒ‡å®šã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€LightGBMãŒæ‰±ãˆã‚‹ã‚ˆã†ã«å‰å‡¦ç†ã‚’è¡Œã†ã€‚
    """
    if not data_filepath.exists():
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„: `{data_filepath}`")
        st.stop()
    try:
        df = pd.read_csv(data_filepath, index_col='Date', parse_dates=True)
        df.dropna(axis='columns', how='all', inplace=True)
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        st.success(f"ãƒ‡ãƒ¼ã‚¿ '{data_filepath.name}' ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚è¡Œæ•°: {len(df)}")
        return df
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.stop()

@st.cache_data
def load_model_performance(perf_filepath):
    """
    æŒ‡å®šã•ã‚ŒãŸJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    if not perf_filepath.exists():
        st.warning(f"è­¦å‘Š: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹: `{perf_filepath}`")
        return None
    try:
        with open(perf_filepath, 'r') as f:
            perf_data = json.load(f)
        st.success(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ '{perf_filepath.name}' ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return perf_data
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ•ã‚¡ã‚¤ãƒ« '{perf_filepath.name}' ã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
        return None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# --- Streamlit UIã®æ§‹ç¯‰ ---

st.title("ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€éå»ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã«åŸºã¥ã„ã¦å°†æ¥ã®æ ªä¾¡ï¼ˆæŒ‡å®šã•ã‚ŒãŸæœŸé–“ã§ã®ä¸Šæ˜‡ï¼‰ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

st.sidebar.header("ã‚¢ãƒ—ãƒªæƒ…å ±")
st.sidebar.write(f"ãƒ¢ãƒ‡ãƒ«/ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: `{MODELS_DIR}`")
st.sidebar.write(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: `{DATA_DIR}`")
st.sidebar.write(f"LightGBMãƒãƒ¼ã‚¸ãƒ§ãƒ³: `{lgb.__version__}`")
st.sidebar.markdown("---")

st.header("éŠ˜æŸ„ã¨äºˆæ¸¬æœŸé–“ã®é¸æŠ")

# 1. åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã®å–å¾—
available_stocks = []
if DATA_DIR.exists():
    available_data_files = [f for f in os.listdir(DATA_DIR) if f.endswith('_modified.csv')]
    if available_data_files:
        available_stocks = sorted([f.replace('_modified.csv', '') for f in available_data_files])
    else:
        st.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{DATA_DIR}' ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{DATA_DIR}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å‰ã«ã€`data/modified` ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

selected_stock = st.selectbox(
    "äºˆæ¸¬ã—ãŸã„éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=available_stocks,
    index=0 if available_stocks else None
)

df_selected_stock = pd.DataFrame()
if selected_stock:
    selected_data_filepath = DATA_DIR / f"{selected_stock}_modified.csv"
    df_selected_stock = load_stock_data(selected_data_filepath)
else:
    st.warning("é¸æŠã§ãã‚‹éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# 2. åˆ©ç”¨å¯èƒ½ãªã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ã®å–å¾—
available_target_periods = []
if MODELS_DIR.exists():
    # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸¡æ–¹ã‹ã‚‰æœŸé–“ã‚’æŠ½å‡ºã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ã«å¤‰æ›´
    available_model_files = [f for f in os.listdir(MODELS_DIR) if f.startswith(f"lgbm_model_{selected_stock}_") and f.endswith('.joblib')]
    available_metrics_files = [f for f in os.listdir(MODELS_DIR) if f.startswith(f"{selected_stock}_") and f.endswith('_metrics.json')] # æ–°ã—ã„å‘½åè¦å‰‡ã«å¯¾å¿œ

    # joblibãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœŸé–“ã‚’æŠ½å‡º
    periods_from_models = {
        int(f.replace(f"lgbm_model_{selected_stock}_", "").replace("d.joblib", ""))
        for f in available_model_files
        if f.replace(f"lgbm_model_{selected_stock}_", "").replace("d.joblib", "").isdigit()
    }
    
    # metrics JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœŸé–“ã‚’æŠ½å‡º (ä¾‹: 1547_120d_metrics.json -> 120)
    periods_from_metrics = {
        int(f.replace(f"{selected_stock}_", "").replace("d_metrics.json", ""))
        for f in available_metrics_files
        if f.replace(f"{selected_stock}_", "").replace("d_metrics.json", "").isdigit()
    }

    # ä¸¡æ–¹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«å­˜åœ¨ã™ã‚‹æœŸé–“ã®ã¿ã‚’å¯¾è±¡ã¨ã™ã‚‹
    available_target_periods = sorted(list(periods_from_models.intersection(periods_from_metrics)))

    if not available_target_periods:
        st.warning(f"éŠ˜æŸ„ '{selected_stock}' ã«å¯¾å¿œã™ã‚‹æœ‰åŠ¹ãªãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{MODELS_DIR}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å‰ã«ã€`models` ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

model = None
trained_feature_names = None
model_performance_data = None

if available_target_periods:
    selected_target_period = st.selectbox(
        "äºˆæ¸¬ã—ãŸã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ (Næ—¥å¾Œã®ä¸Šæ˜‡) ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        options=available_target_periods,
        index=available_target_periods.index(120) if 120 in available_target_periods else 0
    )

    # é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹ã‚’æ§‹ç¯‰
    selected_model_filename = f"lgbm_model_{selected_stock}_{selected_target_period}d.joblib"
    selected_model_path = MODELS_DIR / selected_model_filename
    
    # ãƒ¢ãƒ‡ãƒ«ã¨è¨“ç·´æ™‚ã®ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    model, trained_feature_names = load_model_and_features(selected_model_path)

    # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ (æ–°ã—ã„å‘½åè¦å‰‡ã«å¯¾å¿œ)
    selected_perf_filename = f"{selected_stock}_{selected_target_period}d_metrics.json" # ã‚µãƒ³ãƒ—ãƒ«JSONã®å‘½åè¦å‰‡ã«åˆã‚ã›ã‚‹
    selected_perf_filepath = MODELS_DIR / selected_perf_filename # MODELS_DIR ã«ã‚ã‚‹ã¨ä»®å®š
    model_performance_data = load_model_performance(selected_perf_filepath)

else:
    st.warning("é¸æŠã§ãã‚‹ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

st.header("äºˆæ¸¬å®Ÿè¡Œ")

features_for_prediction = []
if trained_feature_names is not None and not df_selected_stock.empty:
    features_for_prediction = [col for col in trained_feature_names if col in df_selected_stock.columns]
    missing_features = [col for col in trained_feature_names if col not in df_selected_stock.columns]
    if missing_features:
        st.warning(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚ŒãŸéš›ã®ç‰¹å¾´é‡ã®ä¸€éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_features)}ã€‚äºˆæ¸¬ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    if not features_for_prediction:
        st.error("ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ç‰¹å¾´é‡ã¨ä¸€è‡´ã™ã‚‹åˆ—ãŒã€é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
        st.stop()
elif trained_feature_names is None:
    st.error("ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
    st.stop()
elif df_selected_stock.empty:
    st.error("éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
    st.stop()

# äºˆæ¸¬å¯¾è±¡æ—¥ã®é¸æŠ
available_dates = df_selected_stock.index.unique().sort_values(ascending=False)

if available_dates.empty:
    st.warning("é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    st.stop()

default_date_index = 0
selected_date = st.selectbox(
    "äºˆæ¸¬ã‚’è¡Œã„ãŸã„æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ (ã“ã®æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã—ã¾ã™):",
    options=available_dates.date,
    index=default_date_index
)

prediction_data_series = df_selected_stock.loc[pd.to_datetime(selected_date)]
X_predict = pd.DataFrame([prediction_data_series[features_for_prediction].values], columns=features_for_prediction)

st.subheader(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ ({selected_stock}) - {selected_date} ã®ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
display_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
indicator_display_cols = [f for f in features_for_prediction if any(f.startswith(prefix) for prefix in ['SMA', 'RSI', 'MACD', 'stoch', 'BBANDS'])]
display_cols.extend(indicator_display_cols[:5])
existing_display_cols = [col for col in display_cols if col in prediction_data_series.keys()]

if not existing_display_cols:
    st.warning("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.dataframe(prediction_data_series[existing_display_cols].to_frame().T)
st.markdown("---")

# äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ“ˆ æ ªä¾¡ä¸Šæ˜‡ã‚’äºˆæ¸¬ã™ã‚‹"):
    with st.spinner("äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
        if X_predict.isnull().any().any():
            st.warning("é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®NaNã¯äºˆæ¸¬å‰ã«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‡¦ç†ã•ã‚Œã¾ã™ãŒã€ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        prediction_proba = model.predict_proba(X_predict)[:, 1][0]
        prediction_class = model.predict(X_predict)[0]

        st.subheader("äºˆæ¸¬çµæœ")
        if prediction_class == 1:
            st.success(f"**ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒ{selected_target_period}æ—¥ä»¥å†…ã«ä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ï¼**")
            st.metric(f"{selected_target_period}æ—¥å¾Œã®ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")
        else:
            st.info(f"**ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«/ãƒã‚¬ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒ{selected_target_period}æ—¥ä»¥å†…ã«ä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚**")
            st.metric(f"{selected_target_period}æ—¥å¾Œã®ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")

        st.markdown("---")
        st.subheader("ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™")
        if model_performance_data:
            st.write("---")
            st.write(f"**ç·åˆè©•ä¾¡:**")
            st.write(f"- **ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®ç²¾åº¦ (Accuracy):** `{model_performance_data.get('accuracy', 'N/A'):.2f}`")
            st.write(f"- **ROC AUC ã‚¹ã‚³ã‚¢:** `{model_performance_data.get('roc_auc_score', 'N/A'):.2f}`")
            st.write("---")
            st.write(f"**ã‚¯ãƒ©ã‚¹ã”ã¨ã®è©³ç´° (0: ä¸Šæ˜‡ã—ãªã„, 1: ä¸Šæ˜‡ã™ã‚‹):**")
            
            # ã‚¯ãƒ©ã‚¹0ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            class_0 = model_performance_data.get('class_0_metrics', {})
            st.markdown(f"**ã‚¯ãƒ©ã‚¹ 0 (ä¸Šæ˜‡ã—ãªã„) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
            st.write(f"- é©åˆç‡ (Precision): `{class_0.get('precision', 'N/A'):.2f}`")
            st.write(f"- å†ç¾ç‡ (Recall): `{class_0.get('recall', 'N/A'):.2f}`")
            st.write(f"- F1ã‚¹ã‚³ã‚¢: `{class_0.get('f1-score', 'N/A'):.2f}`")
            st.write(f"- ã‚µãƒãƒ¼ãƒˆæ•°: `{int(class_0.get('support', 0))}`") # supportã¯æ•´æ•°ã§è¡¨ç¤º

            st.markdown(f"**ã‚¯ãƒ©ã‚¹ 1 (ä¸Šæ˜‡ã™ã‚‹) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
            class_1 = model_performance_data.get('class_1_metrics', {})
            st.write(f"- é©åˆç‡ (Precision): `{class_1.get('precision', 'N/A'):.2f}`")
            st.write(f"- å†ç¾ç‡ (Recall): `{class_1.get('recall', 'N/A'):.2f}`")
            st.write(f"- F1ã‚¹ã‚³ã‚¢: `{class_1.get('f1-score', 'N/A'):.2f}`")
            st.write(f"- ã‚µãƒãƒ¼ãƒˆæ•°: `{int(class_1.get('support', 0))}`") # supportã¯æ•´æ•°ã§è¡¨ç¤º

            st.markdown("---")
            st.write("**æ··åŒè¡Œåˆ—:**")
            cm = model_performance_data.get('confusion_matrix', [[0,0],[0,0]])
            st.dataframe(pd.DataFrame(cm, columns=['Predicted 0', 'Predicted 1'], index=['Actual 0', 'Actual 1']))
            
            st.caption("â€»ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ»è©•ä¾¡ã•ã‚ŒãŸéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")
            st.caption("â€»é©åˆç‡(Precision)ã¯ã€Œé™½æ€§ã¨äºˆæ¸¬ã—ãŸä¸­ã§å®Ÿéš›ã«é™½æ€§ã ã£ãŸå‰²åˆã€ã€å†ç¾ç‡(Recall)ã¯ã€Œå®Ÿéš›ã«é™½æ€§ã ã£ãŸã‚‚ã®ã‚’ã©ã‚Œã ã‘é™½æ€§ã¨äºˆæ¸¬ã§ããŸã‹ã€ã‚’ç¤ºã—ã¾ã™ã€‚")
            st.caption("â€»ROC AUCã‚¹ã‚³ã‚¢ã¯ãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡æ€§èƒ½ã®ãƒãƒ©ãƒ³ã‚¹ã‚’ç¤ºã™æŒ‡æ¨™ã§ã™ã€‚")
        else:
            st.warning("ã“ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.markdown("---")
        st.subheader("äºˆæ¸¬ã«å½±éŸ¿ã—ãŸç‰¹å¾´é‡")
        if hasattr(model, 'feature_importances_') and trained_feature_names is not None:
            feature_importance = pd.Series(model.feature_importances_, index=trained_feature_names)
            top_features = feature_importance.nlargest(15)
            st.bar_chart(top_features)
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.markdown("---")
        st.info("â€» ã“ã®äºˆæ¸¬ã¯ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ãŸã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®æ ªä¾¡ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")
