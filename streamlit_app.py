# streamlit_app.py (å…¨æ©Ÿèƒ½ã‚’å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«é›†ç´„ - æ—¥æœ¬èªè¡¨è¨˜ & å¯è¦–æ€§å‘ä¸Š & ç‰¹å¾´é‡é‡è¦åº¦ & ç›®æ¬¡æ©Ÿèƒ½)

import streamlit as st
import pandas as pd
import joblib
import numpy as np
import requests
import json
from pathlib import Path
import matplotlib.pyplot as plt
import mplfinance as mpf
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã¨æç”»è¨­å®š ---
import japanize_matplotlib

# matplotlibã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’è‡ªå‹•ã§è¡Œã†
japanize_matplotlib.japanize()

# ç‰¹å®šã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã™ã‚‹è¨­å®š
plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'IPAexGothic', 'Hiragino Sans', 'Meiryo', 'Yu Gothic', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False # è² ã®ç¬¦å·ã®æ–‡å­—åŒ–ã‘é˜²æ­¢

# --- è¨­å®š ---
GITHUB_RAW_URL_BASE = "https://raw.githubusercontent.com/yuutaka69/kabuka_agaru/main/"
ALL_PERFORMANCE_JSON_URL = f"{GITHUB_RAW_URL_BASE}models/all_stock_model_performance.json"

# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰é–¢æ•° (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ã) ---

@st.cache_data
def load_all_performance_data_from_github():
    """
    GitHubã‹ã‚‰å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    """
    try:
        response = requests.get(ALL_PERFORMANCE_JSON_URL)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        perf_data = response.json()
        st.success(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ '{Path(ALL_PERFORMANCE_JSON_URL).name}' ã‚’GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return perf_data
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

@st.cache_resource
def load_model_and_features_from_github(stock_code, target_period):
    """
    GitHubã‹ã‚‰ç‰¹å®šã®LightGBMãƒ¢ãƒ‡ãƒ«ã¨è¨“ç·´æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    """
    model_filename = f"lgbm_model_{stock_code}_{target_period}d.joblib"
    model_url = f"{GITHUB_RAW_URL_BASE}models/{model_filename}"

    try:
        response = requests.get(model_url)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        
        from io import BytesIO
        loaded_content = joblib.load(BytesIO(response.content))

        if isinstance(loaded_content, tuple) and len(loaded_content) == 2:
            model, feature_names = loaded_content
            return model, feature_names
        else:
            st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_filename}' ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒã‚»ãƒƒãƒˆã§ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None, None
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ« '{model_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return None, None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

@st.cache_data
def load_stock_data_from_github(stock_code):
    """
    GitHubã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸéŠ˜æŸ„ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    OHLCVãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€Streamlitã‚¢ãƒ—ãƒªã®ãƒãƒ£ãƒ¼ãƒˆæç”»ã«ä½¿ç”¨ã—ã¾ã™ã€‚
    """
    data_filename = f"{stock_code}_modified.csv" # OHLCVã®ã¿ã«çµã‚‰ã‚ŒãŸCSVã‚’æƒ³å®š
    data_url = f"{GITHUB_RAW_URL_BASE}data/modified/{data_filename}"
    
    try:
        df = pd.read_csv(data_url, index_col='Date', parse_dates=True)
        # modified.csvã¯æ—¢ã«OHLCVã«çµã‚‰ã‚Œã¦ã„ã‚‹ãŸã‚ã€ã“ã“ã§ã¯åˆ—ã®å†é¸æŠã¯ä¸è¦ã ãŒã€
        # å¿µã®ãŸã‚æœ€ä½é™ã®OHLCVåˆ—ãŒã‚ã‚‹ã‹ç¢ºèª
        required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
        if not all(col in df.columns for col in required_cols):
            st.warning(f"è­¦å‘Š: '{data_filename}' ã«å¿…è¦ãªOHLCVåˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
            # ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯æœ€ä½é™ã®åˆ—ã®ã¿ã§ç¶šè¡Œã€ã¾ãŸã¯ã‚¨ãƒ©ãƒ¼
            df = df[required_cols] # å­˜åœ¨ã—ãªã„åˆ—ã¯NaNã«ãªã‚‹
            
        df.dropna(axis='columns', how='all', inplace=True) # å…¨ã¦NaNã®åˆ—ã‚’å‰Šé™¤
        df.replace([np.inf, -np.inf], np.nan, inplace=True) # ç„¡é™å¤§å€¤ã‚’NaNã«
        return df
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ '{data_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

def get_dynamic_threshold_from_metrics(metrics_data):
    """
    è©•ä¾¡æŒ‡æ¨™è¾æ›¸ã‹ã‚‰å‹•çš„é–¾å€¤ã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸æ–‡å­—åˆ—ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    ä¾‹: 'target_14d_4.7p' -> '4.7p'
    """
    if 'target_column_name' in metrics_data:
        full_target_name = metrics_data['target_column_name']
        parts = full_target_name.split('_')
        # parts[2]ãŒå­˜åœ¨ã—ã€'p'ã§çµ‚ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        if len(parts) > 2 and parts[2].endswith('p'):
            return parts[2]
    return "N/A"

def display_metrics_and_confusion_matrix(metrics, title, is_recent=False):
    """
    è©•ä¾¡æŒ‡æ¨™ã¨æ··åŒè¡Œåˆ—ã‚’è¡¨ç¤ºã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã€‚
    æŒ‡æ¨™ã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã§è¡¨ç¤ºã•ã‚Œã€æ··åŒè¡Œåˆ—ã¯Plotlyã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
    """
    if not metrics:
        st.warning(f"{title}ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.markdown(f"**{title}ã®æŒ‡æ¨™:**")
    
    col_m1, col_m2 = st.columns(2)
    with col_m1:
        # Check for NaN before passing to progress bar
        accuracy_val = float(metrics.get('accuracy', 0)) if not np.isnan(metrics.get('accuracy', np.nan)) else 0
        st.progress(accuracy_val, text=f"ç²¾åº¦: {metrics.get('accuracy', np.nan):.2f}")
        
        roc_auc_val = float(metrics.get('roc_auc_score', 0)) if not np.isnan(metrics.get('roc_auc_score', np.nan)) else 0
        st.progress(roc_auc_val, text=f"ROC AUC: {metrics.get('roc_auc_score', np.nan):.2f}")
    with col_m2:
        if is_recent: # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            precision_val = float(metrics.get('precision_class_1', 0)) if not np.isnan(metrics.get('precision_class_1', np.nan)) else 0
            st.progress(precision_val, text=f"é©åˆç‡(ã‚¯ãƒ©ã‚¹1): {metrics.get('precision_class_1', np.nan):.2f}")
            
            recall_val = float(metrics.get('recall_class_1', 0)) if not np.isnan(metrics.get('recall_class_1', np.nan)) else 0
            st.progress(recall_val, text=f"å†ç¾ç‡(ã‚¯ãƒ©ã‚¹1): {metrics.get('recall_class_1', np.nan):.2f}")
            
            f1_val = float(metrics.get('f1_score_class_1', 0)) if not np.isnan(metrics.get('f1_score_class_1', np.nan)) else 0
            st.progress(f1_val, text=f"F1ã‚¹ã‚³ã‚¢(ã‚¯ãƒ©ã‚¹1): {metrics.get('f1_score_class_1', np.nan):.2f}")
        else: # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å ´åˆ
            class_1_metrics = metrics.get('class_1_metrics', {})
            
            precision_val = float(class_1_metrics.get('precision', 0)) if not np.isnan(class_1_metrics.get('precision', np.nan)) else 0
            st.progress(precision_val, text=f"é©åˆç‡(ã‚¯ãƒ©ã‚¹1): {class_1_metrics.get('precision', np.nan):.2f}")
            
            recall_val = float(class_1_metrics.get('recall', 0)) if not np.isnan(class_1_metrics.get('recall', np.nan)) else 0
            st.progress(recall_val, text=f"å†ç¾ç‡(ã‚¯ãƒ©ã‚¹1): {class_1_metrics.get('recall', np.nan):.2f}")
            
            f1_val = float(class_1_metrics.get('f1-score', 0)) if not np.isnan(class_1_metrics.get('f1-score', np.nan)) else 0
            st.progress(f1_val, text=f"F1ã‚¹ã‚³ã‚¢(ã‚¯ãƒ©ã‚¹1): {class_1_metrics.get('f1-score', np.nan):.2f}")
            
    # Confusion Matrix using Plotly
    cm = metrics.get('confusion_matrix', None)
    if cm:
        st.markdown(f"**{title} æ··åŒè¡Œåˆ—:**")
        cm_df = pd.DataFrame(cm, 
                             index=['å®Ÿéš›: éä¸Šæ˜‡ (0)', 'å®Ÿéš›: ä¸Šæ˜‡ (1)'],
                             columns=['äºˆæ¸¬: éä¸Šæ˜‡ (0)', 'äºˆæ¸¬: ä¸Šæ˜‡ (1)'])

        fig_cm = go.Figure(data=go.Heatmap(
            z=cm_df.values,
            x=cm_df.columns,
            y=cm_df.index,
            colorscale='Blues',
            text=cm_df.values,
            texttemplate="%{text}",
            textfont={"size":16}
        ))
        
        fig_cm.update_layout(
            title_text=title,
            xaxis_title="äºˆæ¸¬",
            yaxis_title="å®Ÿéš›",
            xaxis_showgrid=False,
            yaxis_showgrid=False,
            yaxis_autorange='reversed', # 'å®Ÿéš›: éä¸Šæ˜‡' ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ã™ã‚‹
            height=350, # Set a fixed height
            margin=dict(l=50, r=50, t=50, b=50) # Adjust margins
        )
        st.plotly_chart(fig_cm, use_container_width=True)
    else:
        st.warning(f"{title}ã®æ··åŒè¡Œåˆ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# --- Streamlit UIè¨­å®š ---

st.set_page_config(
    layout="wide",
    page_title="æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€**GitHubã«ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡çµæœ**ã‚’ä½¿ç”¨ã—ã¦ã€æ ªä¾¡äºˆæ¸¬æƒ…å ±ã‚’æä¾›ã—ã¾ã™ã€‚")

# å…¨ã¦ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸãƒ­ãƒ¼ãƒ‰
all_performance_data = load_all_performance_data_from_github()

if all_performance_data is None:
    st.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

# åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
available_stocks = sorted(list(all_performance_data.keys()))

if not available_stocks:
    st.error("GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã«éŠ˜æŸ„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«éŠ˜æŸ„é¸æŠã‚’é…ç½®
st.sidebar.header("éŠ˜æŸ„é¸æŠ")
selected_stock = st.sidebar.selectbox(
    "åˆ†æã—ãŸã„éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=available_stocks,
    index=0
)

# ã‚¿ãƒ–ã®ä½œæˆ
tab1, tab2 = st.tabs(["ğŸ“Š ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ğŸ“ˆ å€‹åˆ¥éŠ˜æŸ„è©³ç´°"])

# --- Tab 1: Ranking Display ---
with tab1:
    st.header("ğŸ“Š æ ªä¾¡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ« ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    st.markdown("ã“ã“ã§ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°å½¢å¼ã§ç¢ºèªã§ãã¾ã™ã€‚")

    ranking_data = []
    for stock_code, periods_data in all_performance_data.items():
        for period_str, model_data in periods_data.items():
            training_eval = model_data.get('training_evaluation', {})
            recent_eval = model_data.get('recent_data_evaluation', {})
            
            # å‹•çš„é–¾å€¤ã‚’å–å¾— (training_eval ã‹ã‚‰å„ªå…ˆçš„ã«å–å¾—)
            dynamic_threshold_str = get_dynamic_threshold_from_metrics(training_eval)
            if dynamic_threshold_str == "N/A": # training_evalã«ãªã‘ã‚Œã° recent_eval ã‚’ç¢ºèª
                dynamic_threshold_str = get_dynamic_threshold_from_metrics(recent_eval)

            ranking_data.append({
                'éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰': stock_code,
                'äºˆæ¸¬æœŸé–“ (æ—¥)': int(period_str.replace('d', '')),
                'ä¸Šæ˜‡é–¾å€¤ (%)': dynamic_threshold_str.replace('p', ''), # 'p' ã‚’é™¤å»ã—ã¦è¡¨ç¤º
                'è¨“ç·´Acc': training_eval.get('accuracy', np.nan),
                'è¨“ç·´AUC': training_eval.get('roc_auc_score', np.nan),
                'è¨“ç·´F1(1)': training_eval.get('class_1_metrics', {}).get('f1-score', np.nan),
                'ç›´è¿‘Acc': recent_eval.get('accuracy', np.nan),
                'ç›´è¿‘AUC': recent_eval.get('roc_auc_score', np.nan),
                'ç›´è¿‘F1(1)': recent_eval.get('f1_score_class_1', np.nan),
                'æœ€çµ‚äºˆæ¸¬æ—¥': recent_eval.get('most_recent_prediction_date', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬å€¤': recent_eval.get('most_recent_prediction_value', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': recent_eval.get('most_recent_prediction_proba', np.nan)
            })

    if ranking_data:
        df_ranking = pd.DataFrame(ranking_data)

        # ã‚½ãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        sort_by_options = {
            "ç›´è¿‘F1(1) (é™é †)": "ç›´è¿‘F1(1)",
            "è¨“ç·´F1(1) (é™é †)": "è¨“ç·´F1(1)",
            "ç›´è¿‘Acc (é™é †)": "ç›´è¿‘Acc",
            "è¨“ç·´Acc (é™é †)": "è¨“ç·´Acc",
            "äºˆæ¸¬æœŸé–“ (æ—¥) (æ˜‡é †)": "äºˆæ¸¬æœŸé–“ (æ—¥)",
            "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ (æ˜‡é †)": "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰"
        }
        
        col1_rank, col2_rank = st.columns([1, 2])
        with col1_rank:
            sort_key_display = st.selectbox("ã‚½ãƒ¼ãƒˆåŸºæº–:", list(sort_by_options.keys()))
        
        sort_column = sort_by_options[sort_key_display]
        ascending = False if "é™é †" in sort_key_display else True

        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’é©åˆ‡ã«ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€NaNã®ã¾ã¾ã«ã—ã¦ãŠã
        numeric_cols = ['è¨“ç·´Acc', 'è¨“ç·´AUC', 'è¨“ç·´F1(1)', 'ç›´è¿‘Acc', 'ç›´è¿‘AUC', 'ç›´è¿‘F1(1)', 'æœ€çµ‚äºˆæ¸¬ç¢ºç‡']
        for col in numeric_cols:
            if col in df_ranking.columns:
                df_ranking[col] = pd.to_numeric(df_ranking[col], errors='coerce')

        # ã‚½ãƒ¼ãƒˆå®Ÿè¡Œ
        df_ranking_sorted = df_ranking.sort_values(by=sort_column, ascending=ascending, na_position='last')

        st.markdown("---")
        st.subheader("å…¨ä½“ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        st.markdown("å„æŒ‡æ¨™ã¯é«˜ã„ã»ã©ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒè‰¯ã„ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚")

        st.dataframe(df_ranking_sorted.style.format({
            'è¨“ç·´Acc': "{:.2f}", 'è¨“ç·´AUC': "{:.2f}", 'è¨“ç·´F1(1)': "{:.2f}",
            'ç›´è¿‘Acc': "{:.2f}", 'ç›´è¿‘AUC': "{:.2f}", 'ç›´è¿‘F1(1)': "{:.2f}",
            'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': "{:.2%}"
        }), use_container_width=True)

        st.caption("**ä¸Šæ˜‡é–¾å€¤ (%)**: Næ—¥å¾Œã«æ ªä¾¡ãŒã“ã®å‰²åˆä»¥ä¸Šä¸Šæ˜‡ã—ãŸå ´åˆã«ã€Œä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ï¼ˆ1ï¼‰ã€ã¨åˆ¤å®šã•ã‚Œã¾ã™ã€‚")
        st.caption("**æœ€çµ‚äºˆæ¸¬å€¤** 1 ã¯ã€Œä¸Šæ˜‡ã€ã‚·ã‚°ãƒŠãƒ«ã€0 ã¯ã€Œéä¸Šæ˜‡ã€ã‚·ã‚°ãƒŠãƒ«ã§ã™ã€‚")
        st.caption("ã€Œç›´è¿‘F1(1)ã€ãŒ NaN ã®å ´åˆã€ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã«ã‚¯ãƒ©ã‚¹1ã®ã‚µãƒ³ãƒ—ãƒ«ãŒãªã‹ã£ãŸã‹ã€è©•ä¾¡ã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

    else:
        st.warning("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚GitHubã®ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- Tab 2: Stock Details ---
with tab2:
    st.header(f"ğŸ“ˆ å€‹åˆ¥éŠ˜æŸ„è©³ç´°åˆ†æ: {selected_stock}")
    st.markdown("é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ã€å„äºˆæ¸¬æœŸé–“ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã¨æœ€æ–°äºˆæ¸¬ã€æ ªä¾¡æ¨ç§»ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

    df_selected_stock = load_stock_data_from_github(selected_stock)

    if df_selected_stock.empty:
        st.error(f"éŠ˜æŸ„ {selected_stock} ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    # ç›´è¿‘ã®æ ªä¾¡æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆã®ã¿è¡¨ç¤º
    st.subheader("ç›´è¿‘ã®æ ªä¾¡æ¨ç§»")
    try:
        mc = mpf.make_marketcolors(up='green', down='red', wick='inherit', edge='inherit', volume='in', inherit=True)
        s = mpf.make_mpf_style(base_mpf_style='yahoo', marketcolors=mc)
        
        chart_data_length = min(len(df_selected_stock), 120) 
        fig, axes = mpf.plot(
            df_selected_stock.tail(chart_data_length), 
            type='candle',
            style=s,
            volume=True,
            figscale=1.5,
            returnfig=True
        )
        st.pyplot(fig)
        plt.close(fig) # ãƒ¡ãƒ¢ãƒªè§£æ”¾
    except Exception as e:
        st.warning(f"æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆã®æç”»ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã‚‹ã‹ã€ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å•é¡ŒãŒã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")


    st.subheader("ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã¨å„æœŸé–“ã®æœ€æ–°äºˆæ¸¬")

    periods_data = all_performance_data.get(selected_stock, {})
    if not periods_data:
        st.warning(f"éŠ˜æŸ„ {selected_stock} ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        sorted_periods = sorted([int(p.replace('d', '')) for p in periods_data.keys()])

        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç›®æ¬¡ã‚’è¿½åŠ 
        st.sidebar.markdown("---")
        st.sidebar.header("æœŸé–“åˆ¥ãƒ¢ãƒ‡ãƒ«æ¦‚è¦")
        for period in sorted_periods:
            st.sidebar.markdown(f"[{period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«](#{period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«)") # ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯
        st.sidebar.markdown("---")

        for target_period in sorted_periods:
            period_str = f"{target_period}d"
            model_data = periods_data[period_str]

            st.markdown(f"---") 
            # ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ãªã‚‹IDã‚’è¨­å®š
            st.markdown(f"<a name='{target_period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«'></a>", unsafe_allow_html=True) 
            st.markdown(f"### {target_period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«") 

            # å‹•çš„é–¾å€¤ã‚’å–å¾—
            dynamic_threshold_str = get_dynamic_threshold_from_metrics(model_data.get('training_evaluation', {}))
            if dynamic_threshold_str == "N/A": 
                dynamic_threshold_str = get_dynamic_threshold_from_metrics(model_data.get('recent_data_evaluation', {}))
            
            st.markdown(f"ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€**{target_period}æ—¥å¾Œã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹ã‹**ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚")

            # --- è¨“ç·´æ™‚è©•ä¾¡ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
            st.markdown("#### è¨“ç·´æ™‚è©•ä¾¡ (ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆ)")
            display_metrics_and_confusion_matrix(model_data.get('training_evaluation', {}), 'è¨“ç·´æ™‚è©•ä¾¡', is_recent=False)

            # --- ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬ã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
            st.markdown("#### ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬")
            recent_metrics = model_data.get('recent_data_evaluation', {})
            
            if recent_metrics:
                # è©•ä¾¡æœŸé–“ã¯ãƒ†ã‚­ã‚¹ãƒˆã§
                st.write(f"**è©•ä¾¡æœŸé–“:** `{recent_metrics.get('total_evaluated_days', 'N/A')}` æ—¥é–“")
                
                # Metrics with progress bars (values are handled to be within 0-1)
                col_rc_metrics1, col_rc_metrics2 = st.columns(2)
                with col_rc_metrics1:
                    # Explicitly handle NaN for progress bar value, keep original for text
                    accuracy_val = float(recent_metrics.get('accuracy', 0)) if not np.isnan(recent_metrics.get('accuracy', np.nan)) else 0
                    st.progress(accuracy_val, text=f"ç²¾åº¦: {recent_metrics.get('accuracy', np.nan):.2f}")
                    
                    roc_auc_val = float(recent_metrics.get('roc_auc_score', 0)) if not np.isnan(recent_metrics.get('roc_auc_score', np.nan)) else 0
                    st.progress(roc_auc_val, text=f"ROC AUC: {recent_metrics.get('roc_auc_score', np.nan):.2f}")
                with col_rc_metrics2:
                    precision_val = float(recent_metrics.get('precision_class_1', 0)) if not np.isnan(recent_metrics.get('precision_class_1', np.nan)) else 0
                    st.progress(precision_val, text=f"é©åˆç‡(ã‚¯ãƒ©ã‚¹1): {recent_metrics.get('precision_class_1', np.nan):.2f}")
                    
                    recall_val = float(recent_metrics.get('recall_class_1', 0)) if not np.isnan(recent_metrics.get('recall_class_1', np.nan)) else 0
                    st.progress(recall_val, text=f"å†ç¾ç‡(ã‚¯ãƒ©ã‚¹1): {recent_metrics.get('recall_class_1', np.nan):.2f}")
                    
                    f1_val = float(recent_metrics.get('f1_score_class_1', 0)) if not np.isnan(recent_metrics.get('f1_score_class_1', np.nan)) else 0
                    st.progress(f1_val, text=f"F1ã‚¹ã‚³ã‚¢(ã‚¯ãƒ©ã‚¹1): {recent_metrics.get('f1_score_class_1', np.nan):.2f}")
                
                st.markdown(f"**æœ€æ–°ã®äºˆæ¸¬ ({recent_metrics.get('most_recent_prediction_date', 'N/A')}ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã):**")
                prediction_value = recent_metrics.get('most_recent_prediction_value', 'N/A')
                prediction_proba = recent_metrics.get('most_recent_prediction_proba', np.nan)
                
                # Prediction probability progress bar (value is handled to be within 0-1)
                proba_val = float(prediction_proba) if not np.isnan(prediction_proba) else 0
                
                if prediction_value == 1:
                    st.success(f"**ğŸ“ˆ ä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«ï¼** ({target_period}æ—¥å¾Œã¾ã§ã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„)")
                    st.progress(proba_val, text=f"äºˆæ¸¬ç¢ºç‡: {prediction_proba:.2%}")
                elif prediction_value == 0:
                    st.info(f"**ğŸ“‰ éä¸Šæ˜‡ã‚·ã‚°ãƒŠãƒ«** ({target_period}æ—¥å¾Œã¾ã§ã«æ ªä¾¡ãŒ{dynamic_threshold_str}ä»¥ä¸Šä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„)")
                    st.progress(proba_val, text=f"äºˆæ¸¬ç¢ºç‡: {prediction_proba:.2%}")
                else:
                    st.warning("æœ€æ–°ã®äºˆæ¸¬å€¤ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

                display_metrics_and_confusion_matrix(recent_metrics, 'ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡', is_recent=True)
            else:
                st.warning("ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã¨æœ€æ–°äºˆæ¸¬ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            # --- Feature Importance Chart ---
            st.markdown("#### ç‰¹å¾´é‡é‡è¦åº¦")
            # `features_used`ã¯training_evaluationã«æ ¼ç´ã•ã‚Œã¦ã„ã‚‹
            features_used = model_data.get('training_evaluation', {}).get('features_used', None)

            if features_used:
                # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
                # Note: This might be slow if models are large and not effectively cached.
                # Consider pre-extracting feature importances to JSON if performance is an issue.
                model_obj, _ = load_model_and_features_from_github(selected_stock, target_period)
                
                if model_obj and hasattr(model_obj, 'feature_importances_'):
                    feature_importance = pd.Series(model_obj.feature_importances_, index=features_used)
                    top_features = feature_importance.nlargest(15) # ä¸Šä½15å€‹ã®ç‰¹å¾´é‡

                    fig_fi = px.bar(
                        top_features,
                        x=top_features.values,
                        y=top_features.index,
                        orientation='h',
                        title='äºˆæ¸¬ã«å½±éŸ¿ã‚’ä¸ãˆãŸä¸Šä½ç‰¹å¾´é‡',
                        labels={'x': 'é‡è¦åº¦', 'y': 'ç‰¹å¾´é‡'},
                        height=400 # ãƒãƒ£ãƒ¼ãƒˆã®é«˜ã•
                    )
                    fig_fi.update_layout(yaxis={'categoryorder':'total ascending'}) # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
                    st.plotly_chart(fig_fi, use_container_width=True)
                else:
                    st.warning("ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
            else:
                st.warning("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")


st.sidebar.markdown("---")
st.sidebar.info("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: GitHubã®å…¬é–‹ãƒªãƒã‚¸ãƒˆãƒª")
st.sidebar.markdown("---")
st.sidebar.write("Developed with â¤ï¸ by Yuu")
