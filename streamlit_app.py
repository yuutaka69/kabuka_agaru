import streamlit as st
import pandas as pd
import joblib
import numpy as np
import os
import lightgbm as lgb
from pathlib import Path
import matplotlib.pyplot as plt
import mplfinance as mpf
import json
import requests # GitHubã‹ã‚‰JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«è¿½åŠ 

# --- è¨­å®š ---
# ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ¢ãƒ‡ãƒ«/ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (Streamlit Cloudãªã©ãƒ‡ãƒ—ãƒ­ã‚¤ç’°å¢ƒã§ã¯èª­ã¿å–ã‚Šå°‚ç”¨ã‹ã€å­˜åœ¨ã—ãªã„å¯èƒ½æ€§ã‚ã‚Š)
MODELS_DIR = Path("models")
DATA_DIR = Path("data/modified")

# GitHubã‹ã‚‰all_stock_model_performance.jsonã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã®URL
# yuutaka69/kabuka_agaru ãƒªãƒã‚¸ãƒˆãƒªã® main ãƒ–ãƒ©ãƒ³ãƒã® models/all_stock_model_performance.json
GITHUB_RAW_URL_BASE = "https://raw.githubusercontent.com/yuutaka69/kabuka_agaru/main/"
ALL_PERFORMANCE_JSON_URL = f"{GITHUB_RAW_URL_BASE}models/all_stock_model_performance.json"

# --- é–¢æ•°: ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰ ---

@st.cache_resource
def load_model_and_features_from_github(stock_code, target_period):
    """
    GitHubã‹ã‚‰ç‰¹å®šã®LightGBMãƒ¢ãƒ‡ãƒ«ã¨è¨“ç·´æ™‚ã«ä½¿ç”¨ã•ã‚ŒãŸç‰¹å¾´é‡ãƒªã‚¹ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    model_filename = f"lgbm_model_{stock_code}_{target_period}d.joblib"
    model_url = f"{GITHUB_RAW_URL_BASE}models/{model_filename}"

    try:
        response = requests.get(model_url)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        
        # joblib.load ã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ãƒ©ã‚¤ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æœŸå¾…ã™ã‚‹ã®ã§ã€BytesIOã‚’ä½¿ã†
        from io import BytesIO
        loaded_content = joblib.load(BytesIO(response.content))

        if isinstance(loaded_content, tuple) and len(loaded_content) == 2:
            model, feature_names = loaded_content
            st.success(f"ãƒ¢ãƒ‡ãƒ« '{model_filename}' ã‚’GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚ç‰¹å¾´é‡æ•°: {len(feature_names)}")
            return model, feature_names
        else:
            st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« '{model_filename}' ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒã‚»ãƒƒãƒˆã§ä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None, None
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ« '{model_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return None, None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

@st.cache_data
def load_stock_data_from_github(stock_code):
    """
    GitHubã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸéŠ˜æŸ„ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€LightGBMãŒæ‰±ãˆã‚‹ã‚ˆã†ã«å‰å‡¦ç†ã‚’è¡Œã†ã€‚
    ã“ã“ã§ã¯äºˆæ¸¬ã«å¿…è¦ãªOpen, High, Low, Close, Volumeä»¥å¤–ã®ç‰¹å¾´é‡ã‚‚ä¿æŒã™ã‚‹ã€‚
    """
    data_filename = f"{stock_code}_modified.csv"
    data_url = f"{GITHUB_RAW_URL_BASE}data/modified/{data_filename}"
    
    try:
        df = pd.read_csv(data_url, index_col='Date', parse_dates=True)
        df.dropna(axis='columns', how='all', inplace=True)
        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        st.success(f"ãƒ‡ãƒ¼ã‚¿ '{data_filename}' ã‚’GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚è¡Œæ•°: {len(df)}")
        return df
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ '{data_filename}' ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.DataFrame()

@st.cache_data
def load_all_performance_data_from_github():
    """
    GitHubã‹ã‚‰å…¨ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã€‚
    """
    try:
        response = requests.get(ALL_PERFORMANCE_JSON_URL)
        response.raise_for_status() # HTTPã‚¨ãƒ©ãƒ¼ã‚’ç¢ºèª
        perf_data = response.json()
        st.sidebar.success(f"ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ '{Path(ALL_PERFORMANCE_JSON_URL).name}' ã‚’GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return perf_data
    except requests.exceptions.RequestException as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½JSONãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚URL: {ALL_PERFORMANCE_JSON_URL}")
        return None
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# --- Streamlit UIã®æ§‹ç¯‰ ---

st.set_page_config(layout="wide", page_title="æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

st.title("ğŸ“ˆ æ ªä¾¡äºˆæ¸¬ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
st.markdown("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€**GitHubã«ä¿å­˜ã•ã‚ŒãŸå­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨è©•ä¾¡çµæœ**ã‚’ä½¿ç”¨ã—ã¦ã€éå»ã®ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ã«åŸºã¥ã„ãŸå°†æ¥ã®æ ªä¾¡ï¼ˆæŒ‡å®šã•ã‚ŒãŸæœŸé–“ã§ã®ä¸Šæ˜‡ï¼‰äºˆæ¸¬ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

st.sidebar.header("ã‚¢ãƒ—ãƒªæƒ…å ±")
st.sidebar.write(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: GitHub ({GITHUB_RAW_URL_BASE.split('//')[1].split('/')[0]})")
st.sidebar.write(f"LightGBMãƒãƒ¼ã‚¸ãƒ§ãƒ³: `{lgb.__version__}`")
st.sidebar.markdown("---")

# å…¨ä½“ã®ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’æœ€åˆã«ãƒ­ãƒ¼ãƒ‰
all_performance_data = load_all_performance_data_from_github()

if all_performance_data is None:
    st.error("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚GitHubã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

st.header("éŠ˜æŸ„ã¨äºˆæ¸¬æœŸé–“ã®é¸æŠ")

# åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ã®ãƒªã‚¹ãƒˆã‚’all_performance_dataã‹ã‚‰å‹•çš„ã«å–å¾—
available_stocks = sorted(list(all_performance_data.keys()))

if not available_stocks:
    st.error("GitHubã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ã«éŠ˜æŸ„æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

selected_stock = st.selectbox(
    "äºˆæ¸¬ã—ãŸã„éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=available_stocks,
    index=0
)

available_target_periods = []
if selected_stock in all_performance_data:
    available_target_periods = sorted([int(p.replace('d', '')) for p in all_performance_data[selected_stock].keys()])

if not available_target_periods:
    st.warning(f"éŠ˜æŸ„ '{selected_stock}' ã«å¯¾å¿œã™ã‚‹äºˆæ¸¬æœŸé–“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

selected_target_period = st.selectbox(
    "äºˆæ¸¬ã—ãŸã„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ (Næ—¥å¾Œã®ä¸Šæ˜‡) ã‚’é¸æŠã—ã¦ãã ã•ã„:",
    options=available_target_periods,
    index=available_target_periods.index(120) if 120 in available_target_periods else 0
)

# é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæœŸé–“ã«å¯¾å¿œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰
model, trained_feature_names = load_model_and_features_from_github(selected_stock, selected_target_period)
df_selected_stock = load_stock_data_from_github(selected_stock)

if model is None or trained_feature_names is None or df_selected_stock.empty:
    st.error("å¿…è¦ãªãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    st.stop()

st.header("äºˆæ¸¬å®Ÿè¡Œ")

features_for_prediction = []
if trained_feature_names is not None and not df_selected_stock.empty:
    features_for_prediction = [col for col in trained_feature_names if col in df_selected_stock.columns]
    missing_features = [col for col in trained_feature_names if col not in df_selected_stock.columns]
    if missing_features:
        st.warning(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚ŒãŸéš›ã®ç‰¹å¾´é‡ã®ä¸€éƒ¨ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {', '.join(missing_features)}ã€‚äºˆæ¸¬ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
    if not features_for_prediction:
        st.error("ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ç‰¹å¾´é‡ã¨ä¸€è‡´ã™ã‚‹åˆ—ãŒã€é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«ã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
        st.stop()
elif trained_feature_names is None:
    st.error("ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡ãƒªã‚¹ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
    st.stop()
elif df_selected_stock.empty:
    st.error("éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚äºˆæ¸¬ã§ãã¾ã›ã‚“ã€‚")
    st.stop()

# äºˆæ¸¬å¯¾è±¡æ—¥ã®é¸æŠ
available_dates = df_selected_stock.index.unique().sort_values(ascending=False)

if available_dates.empty:
    st.warning("é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ã®ãƒ‡ãƒ¼ã‚¿ã«æœ‰åŠ¹ãªæ—¥ä»˜ãŒã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
    st.stop()

default_date_index = 0
selected_date = st.selectbox(
    "äºˆæ¸¬ã‚’è¡Œã„ãŸã„æ—¥ä»˜ã‚’é¸æŠã—ã¦ãã ã•ã„ (ã“ã®æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã—ã¾ã™):",
    options=available_dates.date,
    index=default_date_index
)

# é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€NaNã‚’å‡¦ç†
prediction_data_series = df_selected_stock.loc[pd.to_datetime(selected_date)]

# è¨“ç·´æ™‚ã®ç‰¹å¾´é‡ã¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚«ãƒ©ãƒ ã‚’æ¯”è¼ƒã—ã€ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«èª¿æ•´
X_predict = pd.DataFrame(columns=trained_feature_names) # è¨“ç·´æ™‚ã®ã‚«ãƒ©ãƒ ã§ç©ºã®DFã‚’ä½œæˆ
# æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã€ä¸è¶³ã™ã‚‹ã‚«ãƒ©ãƒ ã‚’NaNã§åŸ‹ã‚ã‚‹
temp_df = pd.DataFrame([prediction_data_series.reindex(features_for_prediction).values], columns=features_for_prediction)
for col in trained_feature_names:
    if col in temp_df.columns:
        X_predict[col] = temp_df[col]
    else:
        X_predict[col] = np.nan # è¨“ç·´æ™‚ã«ã¯ã‚ã£ãŸãŒç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„å ´åˆã€NaNã§åŸ‹ã‚ã‚‹

X_predict.replace([np.inf, -np.inf], np.nan, inplace=True) # NaN/infã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

st.subheader(f"é¸æŠã•ã‚ŒãŸéŠ˜æŸ„ ({selected_stock}) - {selected_date} ã®ãƒ‡ãƒ¼ã‚¿æ¦‚è¦:")
display_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
indicator_display_cols = [f for f in features_for_prediction if any(f.startswith(prefix) for prefix in ['SMA', 'RSI', 'MACD', 'stoch', 'BBANDS', 'adx', 'atr', 'roc'])]
display_cols.extend(indicator_display_cols[:10]) # ä¸Šä½10å€‹ã®æŒ‡æ¨™ã‚’è¡¨ç¤º
existing_display_cols = [col for col in display_cols if col in prediction_data_series.keys()]

if not existing_display_cols:
    st.warning("è¡¨ç¤ºå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.dataframe(prediction_data_series[existing_display_cols].to_frame().T)
st.markdown("---")

# äºˆæ¸¬å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸ“ˆ æ ªä¾¡ä¸Šæ˜‡ã‚’äºˆæ¸¬ã™ã‚‹"):
    with st.spinner("äºˆæ¸¬ã‚’å®Ÿè¡Œä¸­..."):
        if X_predict.isnull().any().any():
            st.warning("é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®ãƒ‡ãƒ¼ã‚¿ã«NaNãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®NaNã¯äºˆæ¸¬å‰ã«ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦å‡¦ç†ã•ã‚Œã¾ã™ãŒã€ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        
        prediction_proba = model.predict_proba(X_predict)[:, 1][0]
        prediction_class = model.predict(X_predict)[0]

        st.subheader("äºˆæ¸¬çµæœ")
        if prediction_class == 1:
            st.success(f"**ãƒã‚¸ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒ{selected_target_period}æ—¥ä»¥å†…ã«ä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ï¼**")
            st.metric(f"{selected_target_period}æ—¥å¾Œã®ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")
        else:
            st.info(f"**ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«/ãƒã‚¬ãƒ†ã‚£ãƒ–ãªã‚·ã‚°ãƒŠãƒ«: æ ªä¾¡ãŒ{selected_target_period}æ—¥ä»¥å†…ã«ä¸Šæ˜‡ã™ã‚‹å¯èƒ½æ€§ã¯ä½ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚**")
            st.metric(f"{selected_target_period}æ—¥å¾Œã®ä¸Šæ˜‡ç¢ºç‡", f"{prediction_proba:.2%}", delta_color="off")

        st.markdown("---")
        st.subheader("ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™")
        
        stock_perf_data = all_performance_data.get(selected_stock, {})
        model_perf_data = stock_perf_data.get(f"{selected_target_period}d", {})

        if model_perf_data:
            st.write(f"#### è¨“ç·´æ™‚è©•ä¾¡ ({selected_target_period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«)")
            training_metrics = model_perf_data.get('training_evaluation', {})
            if training_metrics:
                st.write(f"- **ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§ã®ç²¾åº¦ (Accuracy):** `{training_metrics.get('accuracy', 'N/A'):.2f}`")
                st.write(f"- **ROC AUC ã‚¹ã‚³ã‚¢:** `{training_metrics.get('roc_auc_score', 'N/A'):.2f}`")
                st.markdown(f"**ã‚¯ãƒ©ã‚¹ 1 (ä¸Šæ˜‡ã™ã‚‹) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
                class_1_train = training_metrics.get('class_1_metrics', {})
                st.write(f"- é©åˆç‡ (Precision): `{class_1_train.get('precision', 'N/A'):.2f}`")
                st.write(f"- å†ç¾ç‡ (Recall): `{class_1_train.get('recall', 'N/A'):.2f}`")
                st.write(f"- F1ã‚¹ã‚³ã‚¢: `{class_1_train.get('f1-score', 'N/A'):.2f}`")
                st.caption("â€»ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ»è©•ä¾¡ã•ã‚ŒãŸéš›ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")
            else:
                st.warning("è¨“ç·´æ™‚è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            
            st.write(f"#### ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ ({selected_target_period}æ—¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«)")
            recent_metrics = model_perf_data.get('recent_data_evaluation', {})
            if recent_metrics:
                st.write(f"- **è©•ä¾¡æœŸé–“ (æ—¥æ•°):** `{recent_metrics.get('total_evaluated_days', 'N/A')}`")
                st.write(f"- **ç²¾åº¦ (Accuracy):** `{recent_metrics.get('accuracy', 'N/A'):.2f}`")
                st.write(f"- **ROC AUC ã‚¹ã‚³ã‚¢:** `{recent_metrics.get('roc_auc_score', 'N/A'):.2f}`")
                st.markdown(f"**ã‚¯ãƒ©ã‚¹ 1 (ä¸Šæ˜‡ã™ã‚‹) ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹:**")
                class_1_recent = recent_metrics.get('class_1_metrics', {}) # all_stock_model_performance.json ã« class_1_metrics ãŒãªã„å ´åˆã¯ã€å€‹åˆ¥ã®ã‚­ãƒ¼ã‚’å‚ç…§
                st.write(f"- é©åˆç‡ (Precision): `{recent_metrics.get('precision_class_1', 'N/A'):.2f}`")
                st.write(f"- å†ç¾ç‡ (Recall): `{recent_metrics.get('recall_class_1', 'N/A'):.2f}`")
                st.write(f"- F1ã‚¹ã‚³ã‚¢: `{recent_metrics.get('f1_score_class_1', 'N/A'):.2f}`")
                st.write(f"- **ç›´è¿‘æœ€çµ‚æ—¥ã®äºˆæ¸¬æ—¥:** `{recent_metrics.get('most_recent_prediction_date', 'N/A')}`")
                st.write(f"- **ç›´è¿‘æœ€çµ‚æ—¥ã®äºˆæ¸¬çµæœ:** `{recent_metrics.get('most_recent_prediction_value', 'N/A')}` (`{recent_metrics.get('most_recent_prediction_proba', 'N/A'):.2%}`)")
                st.caption("â€»ã“ã‚Œã‚‰ã®æŒ‡æ¨™ã¯ãƒ¢ãƒ‡ãƒ«ãŒè©•ä¾¡ã•ã‚ŒãŸç›´è¿‘ã®æœŸé–“ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚")
            else:
                st.warning("ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("ã“ã®ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ãƒ‡ãƒ¼ã‚¿ãŒå…¨ä½“JSONã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.markdown("---")
        st.subheader("äºˆæ¸¬ã«å½±éŸ¿ã—ãŸç‰¹å¾´é‡")
        if hasattr(model, 'feature_importances_') and trained_feature_names is not None:
            feature_importance = pd.Series(model.feature_importances_, index=trained_feature_names)
            top_features = feature_importance.nlargest(15)
            st.bar_chart(top_features)
        else:
            st.warning("ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        st.markdown("---")
        st.info("â€» ã“ã®äºˆæ¸¬ã¯ãƒ¢ãƒ‡ãƒ«ã«åŸºã¥ã„ãŸã‚‚ã®ã§ã‚ã‚Šã€å°†æ¥ã®æ ªä¾¡ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æŠ•è³‡ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å…¨ä½“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤º ---
st.sidebar.header("å…¨ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°")

if all_performance_data:
    ranking_data = []
    for stock_code, periods_data in all_performance_data.items():
        for period_str, model_data in periods_data.items():
            training_eval = model_data.get('training_evaluation', {})
            recent_eval = model_data.get('recent_data_evaluation', {})

            # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ã®F1ã‚¹ã‚³ã‚¢ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨ã€ãªã‘ã‚Œã°è¨“ç·´æ™‚ã®F1ã‚¹ã‚³ã‚¢
            f1_score_recent_class1 = recent_eval.get('f1_score_class_1', np.nan)
            if pd.isna(f1_score_recent_class1): # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿è©•ä¾¡ãŒãªã‘ã‚Œã°è¨“ç·´æ™‚è©•ä¾¡ã‹ã‚‰
                f1_score_recent_class1 = training_eval.get('class_1_metrics', {}).get('f1-score', np.nan)

            ranking_data.append({
                'éŠ˜æŸ„': stock_code,
                'æœŸé–“': int(period_str.replace('d', '')),
                'è¨“ç·´Acc': training_eval.get('accuracy', np.nan),
                'è¨“ç·´AUC': training_eval.get('roc_auc_score', np.nan),
                'è¨“ç·´F1(1)': training_eval.get('class_1_metrics', {}).get('f1-score', np.nan),
                'ç›´è¿‘Acc': recent_eval.get('accuracy', np.nan),
                'ç›´è¿‘AUC': recent_eval.get('roc_auc_score', np.nan),
                'ç›´è¿‘F1(1)': recent_eval.get('f1_score_class_1', np.nan),
                'æœ€çµ‚äºˆæ¸¬æ—¥': recent_eval.get('most_recent_prediction_date', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬': recent_eval.get('most_recent_prediction_value', 'N/A'),
                'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': recent_eval.get('most_recent_prediction_proba', np.nan)
            })

    if ranking_data:
        df_ranking = pd.DataFrame(ranking_data)
        df_ranking.fillna('N/A', inplace=True) # NaNã‚’'N/A'ã«ç½®æ›ã—ã¦è¡¨ç¤ºã‚’ãã‚Œã„ã«

        # ã‚½ãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
        sort_by_options = {
            "ç›´è¿‘F1(1) (é™é †)": "ç›´è¿‘F1(1)",
            "è¨“ç·´F1(1) (é™é †)": "è¨“ç·´F1(1)",
            "ç›´è¿‘Acc (é™é †)": "ç›´è¿‘Acc",
            "è¨“ç·´Acc (é™é †)": "è¨“ç·´Acc",
            "éŠ˜æŸ„ (æ˜‡é †)": "éŠ˜æŸ„"
        }
        sort_by = st.sidebar.selectbox("ã‚½ãƒ¼ãƒˆåŸºæº–:", list(sort_by_options.keys()))
        
        ascending = False if "é™é †" in sort_by else True
        sort_column = sort_by_options[sort_by]

        # æ•°å€¤ã‚«ãƒ©ãƒ ã‚’é©åˆ‡ã«ã‚½ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã«ã€N/Aã‚’NaNã«æˆ»ã—ã¦ã‚½ãƒ¼ãƒˆ
        if sort_column in ['è¨“ç·´Acc', 'è¨“ç·´AUC', 'è¨“ç·´F1(1)', 'ç›´è¿‘Acc', 'ç›´è¿‘AUC', 'ç›´è¿‘F1(1)', 'æœ€çµ‚äºˆæ¸¬ç¢ºç‡']:
            df_ranking[sort_column] = pd.to_numeric(df_ranking[sort_column], errors='coerce')
            df_ranking_sorted = df_ranking.sort_values(by=sort_column, ascending=ascending, na_position='last')
        else:
            df_ranking_sorted = df_ranking.sort_values(by=sort_column, ascending=ascending)

        st.sidebar.dataframe(df_ranking_sorted.head(20).style.format({
            'è¨“ç·´Acc': "{:.2f}", 'è¨“ç·´AUC': "{:.2f}", 'è¨“ç·´F1(1)': "{:.2f}",
            'ç›´è¿‘Acc': "{:.2f}", 'ç›´è¿‘AUC': "{:.2f}", 'ç›´è¿‘F1(1)': "{:.2f}",
            'æœ€çµ‚äºˆæ¸¬ç¢ºç‡': "{:.2%}"
        }))
        st.sidebar.caption("â€» ä¸Šä½20ä»¶ã‚’è¡¨ç¤º")
    else:
        st.sidebar.warning("ãƒ©ãƒ³ã‚­ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
